# ðŸ“¦ Guide : ExÃ©cuter des RequÃªtes SQL Volumineuses

Si vous obtenez l'erreur "Query is too large to be run via the SQL Editor", voici plusieurs solutions.

---

## ðŸŽ¯ Solution 1 : Diviser le SQL en Petits Lots (RecommandÃ©)

### MÃ©thode A : Diviser manuellement

1. **Ouvrez votre fichier SQL** dans un Ã©diteur de texte
2. **Divisez en sections** : Par exemple, 5-10 cours Ã  la fois
3. **Copiez et exÃ©cutez chaque section** sÃ©parÃ©ment dans Supabase SQL Editor

```sql
-- ==========================================
-- LOT 1 : Cours 1 Ã  5
-- ==========================================

-- COURS 1
INSERT INTO courses (...) VALUES (...);

-- LEÃ‡ONS pour COURS 1
INSERT INTO lessons (...) VALUES (...);
INSERT INTO lessons (...) VALUES (...);

-- COURS 2
INSERT INTO courses (...) VALUES (...);
...

-- ==========================================
-- LOT 2 : Cours 6 Ã  10
-- ==========================================
...
```

### MÃ©thode B : Script Python pour diviser automatiquement

CrÃ©ez un fichier `split_sql.py` :

```python
import re

def split_sql_file(input_file, output_dir, courses_per_batch=5):
    """
    Divise un gros fichier SQL en plusieurs petits fichiers
    """
    with open(input_file, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Trouve tous les blocs cours (INSERT INTO courses)
    course_pattern = r'-- COURS \d+.*?(?=-- COURS \d+|$)'
    courses = re.findall(course_pattern, content, re.DOTALL)
    
    total_courses = len(courses)
    batch_num = 1
    
    for i in range(0, total_courses, courses_per_batch):
        batch = courses[i:i+courses_per_batch]
        output_file = f"{output_dir}/batch_{batch_num}.sql"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(f"-- ==========================================\n")
            f.write(f"-- LOT {batch_num} : Cours {i+1} Ã  {min(i+courses_per_batch, total_courses)}\n")
            f.write(f"-- ==========================================\n\n")
            f.write('\n\n'.join(batch))
        
        print(f"âœ… CrÃ©Ã© : {output_file}")
        batch_num += 1
    
    print(f"\nðŸŽ‰ {total_courses} cours divisÃ©s en {batch_num-1} fichiers")

# Utilisation
split_sql_file('cours_complet.sql', 'batches', courses_per_batch=5)
```

ExÃ©cutez :
```bash
python split_sql.py
```

---

## ðŸ”Œ Solution 2 : Utiliser psql (Client PostgreSQL)

### Ã‰tape 1 : Installer psql

**Windows :**
- TÃ©lÃ©chargez PostgreSQL : https://www.postgresql.org/download/windows/
- Ou installez via Chocolatey : `choco install postgresql`

**Mac :**
```bash
brew install postgresql
```

**Linux :**
```bash
sudo apt-get install postgresql-client
```

### Ã‰tape 2 : RÃ©cupÃ©rer les identifiants de connexion

1. Allez sur votre projet Supabase
2. **Settings** â†’ **Database**
3. Trouvez la section **Connection string**
4. Notez :
   - **Host**
   - **Database**
   - **Port**
   - **User**
   - **Password**

### Ã‰tape 3 : Connecter et exÃ©cuter

```bash
# MÃ©thode 1 : Avec mot de passe en ligne de commande
psql "postgresql://postgres:[VOTRE_PASSWORD]@db.[VOTRE_PROJECT_REF].supabase.co:5432/postgres" -f cours_complet.sql

# MÃ©thode 2 : Avec variable d'environnement (plus sÃ»r)
export PGPASSWORD='[VOTRE_PASSWORD]'
psql -h db.[VOTRE_PROJECT_REF].supabase.co -U postgres -d postgres -f cours_complet.sql

# MÃ©thode 3 : Avec fichier .pgpass (recommandÃ© pour la sÃ©curitÃ©)
# CrÃ©ez ~/.pgpass (Linux/Mac) ou %APPDATA%\postgresql\pgpass.conf (Windows)
# Format : hostname:port:database:username:password
echo "db.[VOTRE_PROJECT_REF].supabase.co:5432:postgres:postgres:[VOTRE_PASSWORD]" > ~/.pgpass
chmod 600 ~/.pgpass
psql -h db.[VOTRE_PROJECT_REF].supabase.co -U postgres -d postgres -f cours_complet.sql
```

---

## ðŸ Solution 3 : Utiliser un Script Python avec Supabase

CrÃ©ez un fichier `import_courses.py` :

```python
from supabase import create_client, Client
import re

# Configuration Supabase
SUPABASE_URL = "https://[VOTRE_PROJECT_REF].supabase.co"
SUPABASE_KEY = "[VOTRE_SERVICE_ROLE_KEY]"  # Service Role Key (pas l'anon key)

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def parse_sql_file(filename):
    """
    Parse un fichier SQL et extrait les INSERT statements
    """
    with open(filename, 'r', encoding='utf-8') as f:
        content = f.read()
    
    # Trouve tous les INSERT INTO courses
    course_pattern = r"INSERT INTO courses[^;]+;"
    courses = re.findall(course_pattern, content, re.DOTALL)
    
    # Trouve tous les INSERT INTO lessons
    lesson_pattern = r"INSERT INTO lessons[^;]+;"
    lessons = re.findall(lesson_pattern, content, re.DOTALL)
    
    return courses, lessons

def execute_sql_batch(sql_statements, batch_size=10):
    """
    ExÃ©cute des statements SQL par lots
    """
    for i in range(0, len(sql_statements), batch_size):
        batch = sql_statements[i:i+batch_size]
        batch_sql = '\n'.join(batch)
        
        try:
            result = supabase.rpc('execute_sql', {'sql_query': batch_sql})
            print(f"âœ… Lot {i//batch_size + 1} exÃ©cutÃ© ({len(batch)} statements)")
        except Exception as e:
            print(f"âŒ Erreur lot {i//batch_size + 1}: {e}")
            # Continue avec le lot suivant

# Utilisation
courses, lessons = parse_sql_file('cours_complet.sql')
print(f"ðŸ“š {len(courses)} cours trouvÃ©s")
print(f"ðŸ“ {len(lessons)} leÃ§ons trouvÃ©es")

# ExÃ©cute les cours
print("\nðŸ”„ Insertion des cours...")
execute_sql_batch(courses, batch_size=5)

# ExÃ©cute les leÃ§ons
print("\nðŸ”„ Insertion des leÃ§ons...")
execute_sql_batch(lessons, batch_size=20)
```

**Note :** Cette mÃ©thode nÃ©cessite de crÃ©er une fonction Supabase Edge Function pour exÃ©cuter le SQL.

---

## ðŸ”§ Solution 4 : Utiliser l'API Supabase directement

CrÃ©ez un script Node.js ou Python qui insÃ¨re les donnÃ©es via l'API :

```python
from supabase import create_client, Client
import json

SUPABASE_URL = "https://[VOTRE_PROJECT_REF].supabase.co"
SUPABASE_KEY = "[VOTRE_SERVICE_ROLE_KEY]"

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# Exemple : InsÃ©rer un cours
course_data = {
    "id": "uuid-here",
    "title": "CAF - Guide Complet",
    "slug": "caf-guide-complet",
    "description": "...",
    # ... autres champs
}

try:
    result = supabase.table('courses').insert(course_data).execute()
    print(f"âœ… Cours insÃ©rÃ© : {result.data[0]['title']}")
except Exception as e:
    print(f"âŒ Erreur : {e}")
```

**Avantage :** Pas de limite de taille, mais plus de travail pour parser le SQL.

---

## ðŸ“Š Solution 5 : Utiliser Supabase CLI

### Installation

```bash
npm install -g supabase
```

### Connexion

```bash
supabase login
supabase link --project-ref [VOTRE_PROJECT_REF]
```

### ExÃ©cution

```bash
# ExÃ©cuter directement depuis un fichier
supabase db execute -f cours_complet.sql

# Ou via stdin
cat cours_complet.sql | supabase db execute
```

---

## âœ… Solution RecommandÃ©e : Diviser le SQL

Pour une solution rapide et simple :

1. **Ouvrez votre fichier SQL** gÃ©nÃ©rÃ©
2. **RepÃ©rez les commentaires** `-- COURS 1`, `-- COURS 2`, etc.
3. **Copiez par lots de 5-10 cours** dans Supabase SQL Editor
4. **ExÃ©cutez chaque lot** sÃ©parÃ©ment

### Exemple de division :

```sql
-- ==========================================
-- LOT 1 : Cours 1 Ã  5
-- ==========================================

-- COURS 1
INSERT INTO courses (...) VALUES (...);
-- [toutes les leÃ§ons du cours 1]

-- COURS 2
INSERT INTO courses (...) VALUES (...);
-- [toutes les leÃ§ons du cours 2]

-- ... jusqu'au cours 5

-- ==========================================
-- LOT 2 : Cours 6 Ã  10
-- ==========================================
-- ... etc
```

---

## ðŸŽ¯ Astuce : Modifier le Prompt pour GÃ©nÃ©rer des Lots

Vous pouvez aussi demander Ã  l'IA de gÃ©nÃ©rer le SQL directement par lots :

```
[Votre prompt habituel]

IMPORTANT : Divise le SQL gÃ©nÃ©rÃ© en plusieurs fichiers ou sections :
- Chaque section doit contenir maximum 5 cours avec leurs leÃ§ons
- SÃ©pare chaque section avec un commentaire : -- ==========================================
- NumÃ©rote les sections : -- LOT 1, -- LOT 2, etc.
```

---

## ðŸ“ Checklist

Avant d'exÃ©cuter un gros fichier SQL :

- [ ] VÃ©rifier la taille du fichier (si > 1MB, diviser)
- [ ] Tester sur 1-2 cours d'abord
- [ ] VÃ©rifier que les UUIDs sont uniques
- [ ] VÃ©rifier l'Ã©chappement SQL (apostrophes doublÃ©es)
- [ ] Sauvegarder une copie du fichier original
- [ ] ExÃ©cuter par petits lots si possible

---

## ðŸ†˜ En cas d'erreur

Si vous avez une erreur lors de l'exÃ©cution :

1. **VÃ©rifiez les logs** dans Supabase Dashboard â†’ Logs
2. **Testez avec UN seul cours** d'abord
3. **VÃ©rifiez les contraintes** (UUIDs dupliquÃ©s, clÃ©s Ã©trangÃ¨res)
4. **Utilisez** `ON CONFLICT DO NOTHING` pour Ã©viter les doublons

---

**Besoin d'aide ?** Testez d'abord avec la Solution 1 (division manuelle), c'est la plus simple ! ðŸš€

